{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мова як послідовність\n",
    "\n",
    "## I. Run-on Sentences\n",
    "\n",
    "### 1. Домен\n",
    "\n",
    "Цього тижня ви працюватимете над задачею виправлення помилок.\n",
    "\n",
    "Run-on речення - це речення, склеєне з двох чи більше речень без належної пунктуації. Таку помилку часто допускають механічно, коли швидко друкують текст, проте така помилка виникає і від незнання мови. Особливо часто ця помилка зустрічається в інтернет-спілкуванні.\n",
    "\n",
    "Наприклад:\n",
    "```\n",
    "Thanks for talking to me let's meet again tomorrow Bye.\n",
    "```\n",
    "\n",
    "У цьому реченні насправді три склеєні речення. Правильний варіант:\n",
    "```\n",
    "Thanks for talking to me. Let's meet again tomorrow. Bye.\n",
    "```\n",
    "\n",
    "Run-on речення важливо визначати не лише для виправлення помилок. Ця помилка впливає на якість визначення сутностей, частин мови, синтаксичних зв'язків тощо.\n",
    "\n",
    "Більше інформації та прикладів можна знайти за посиланнями:\n",
    "- http://www.bristol.ac.uk/arts/exercises/grammar/grammar_tutorial/page_37.htm\n",
    "- https://www.english-grammar-revolution.com/run-on-sentence.html\n",
    "- https://www.quickanddirtytips.com/education/grammar/what-are-run-on-sentences\n",
    "\n",
    "### 2. Класифікатор\n",
    "\n",
    "Дані:\n",
    "- Виберіть будь-який відкритий корпус та згенеруйте тренувальні дані для моделі. Тренувальними даними буде набір склеєних речень. Візьміть до уваги, що склеєних речень може бути кілька (зазвичай 2, але буває і 3-4), а перше слово наступного речення може писатися з великої чи малої літери.\n",
    "- Зберіть (чи знайдіть у відкритому доступі) базу енграмів. Візьміть до уваги, що відкриті бази енграмів зазвичай містять статистику, зібрану на реченнях, а отже вони можуть не містити енграми на межі речень.\n",
    "\n",
    "Тестування:\n",
    "- Напишіть бейзлайн та метрику для тестування якості.\n",
    "- Для тестування використайте корпус [run-on-test.json](run-on-test.json). Формат корпусу:\n",
    "```\n",
    "[\n",
    "  [\n",
    "    [\"Thanks\", false],\n",
    "    [\"for\", false],\n",
    "    [\"talking\", false],\n",
    "    [\"to\", false],\n",
    "    [\"me\", true],\n",
    "    [\"let\", false],\n",
    "    [\"'s\", false],\n",
    "    [\"meet\", false],\n",
    "    [\"again\", false],\n",
    "    [\"tomorrow\", true],\n",
    "    [\"Bye\", false],\n",
    "    [\".\", false]\n",
    "  ],\n",
    "...\n",
    "]\n",
    "```\n",
    "\n",
    "`true` позначає слово, на якому закінчується речення. Тестовий корпус містить 200 речень (~ 4700 токенів). 3% токенів мають клас `true`, а решта - `false`.\n",
    "\n",
    "Класифікатор:\n",
    "- Виділіть ознаки, які впливають на те, чи є слово на межі речень. Подумайте про правий/лівий контекст, написання слова, граматичні ознаки (чи може речення закінчитись на сполучник?), енграми (чи часто це слово і наступне йдуть поруч?), складники та залежності тощо.\n",
    "- Побудуйте класифікатор на основі логістичної регресії з використанням виділених ознак, який анотує послідовно слова у реченні на предмет закінчення речення.\n",
    "- Спробуйте покращити якість роботи класифікатора, змінюючи набір чи комбінацію ознак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "1. Dataset of simplified text from wikipedia (for training)\n",
    "\n",
    "Знайшла датасет документів з Simple English Wikipedia, який був створений для Text simplification.<br>\n",
    "Я взяла тільки один файл зі спрощеними реченнями - simple.txt\n",
    "\n",
    "Посилання - http://www.cs.pomona.edu/~dkauchak/simplification/\n",
    "\n",
    "2. Frequent trigrams (for extra feature)\n",
    "\n",
    "Coca 3-grams for words #600-1000 which occur at least 10 times\n",
    "\n",
    "Посилання - https://www.wordfrequency.info/ngrams.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import string\n",
    "import pickle\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\", disable=['tagger', 'parser', 'ner'])\n",
    "\n",
    "def get_data(file='Data/document-aligned.v2/simple.txt'):\n",
    "    with open(file) as f:\n",
    "        prev_subj = 'April'\n",
    "        prev_num = '0'\n",
    "        subject = ''\n",
    "        num = '0'\n",
    "        sentence = ''\n",
    "        paragraphs = []\n",
    "        paragraph = []\n",
    "\n",
    "        for line in f.readlines():\n",
    "            elements = line.rstrip('\\n').split('\\t')\n",
    "            subject = elements[0]\n",
    "            num = elements[1]\n",
    "            sentence = elements[2]\n",
    "            tokens = nlp(sentence)\n",
    "            \n",
    "            if subject != prev_subj and num != prev_num and paragraph:\n",
    "                paragraph[-1][1] = False\n",
    "                paragraph.append(['</p>', False])\n",
    "                \n",
    "                paragraphs.append(paragraph)\n",
    "                paragraph = []\n",
    "            \n",
    "            for i, token in enumerate(tokens[:-1]):  # dot is last character\n",
    "                if not paragraph:\n",
    "                    paragraph.append(['<p>', False])\n",
    "\n",
    "                if i == 0 and len(paragraph) > 1:  # first word of the sentence\n",
    "                    # randomly make a word lower- or upper-case\n",
    "                    random_num = random.randint(0,1)\n",
    "                    if random_num == 1:\n",
    "                        current_token =  token.text.lower()\n",
    "                    else:\n",
    "                        current_token =  token.text.title()\n",
    "                    paragraph.append([current_token, False])\n",
    "                elif i == len(tokens) - 2:\n",
    "                    paragraph.append([token.text, True])\n",
    "                else:\n",
    "                    paragraph.append([token.text, False])\n",
    "            \n",
    "            prev_subj = subject\n",
    "            prev_num = num\n",
    "        return paragraphs\n",
    "    \n",
    "# paragraphs = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<p>', 0],\n",
       " ['April', 0],\n",
       " ['is', 0],\n",
       " ['the', 0],\n",
       " ['fourth', 0],\n",
       " ['month', 0],\n",
       " ['of', 0],\n",
       " ['the', 0],\n",
       " ['year', 1],\n",
       " ['it', 0]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_to_pickle(path, item):\n",
    "    with open(path, 'ab') as file:\n",
    "        pickle.dump(item, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def read_from_pickle(path):\n",
    "    objects = []\n",
    "    with (open(path, \"rb\")) as openfile:\n",
    "        while True:\n",
    "            try:\n",
    "                objects.append(pickle.load(openfile))\n",
    "            except EOFError:\n",
    "                break\n",
    "    return objects\n",
    "\n",
    "\n",
    "# add_to_pickle('Data/procc_dataset.pkl', paragraphs)\n",
    "paragraphs = read_from_pickle('Data/procc_dataset.pkl')[0][0]\n",
    "paragraphs[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequent N-grams Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('free <p>', 564.0),\n",
       " ('free \"', 501.0),\n",
       " ('free the', 225.0),\n",
       " ('free i', 159.0),\n",
       " ('free but', 129.0),\n",
       " ('free and', 125.0),\n",
       " ('free call', 115.0),\n",
       " ('free it', 111.0),\n",
       " ('free he', 91.0),\n",
       " ('free they', 70.0)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_freq_trigrams():\n",
    "    with open('Data/ngrams_alpha.txt', 'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        lines_list = [line.split('\\t') for line in lines]\n",
    "        df = pd.DataFrame(lines_list, columns=['freq', 'w1', 'w2', 'w3'])\n",
    "        df['freq'] = pd.to_numeric(df['freq'])\n",
    "        df['w3'] = df['w3'].map(lambda x: str(x).lower())\n",
    "        df = df[df.apply(lambda x: True if (x['w2']=='.') else False, axis=1)]\n",
    "        df['trigrams_dict'] = df.apply(lambda x: {str(x['w1']) + ' ' +str(x['w3']): x['freq']}, axis=1)\n",
    "    \n",
    "    trigrams_list = df['trigrams_dict'].tolist()\n",
    "    trigrams_dict = {key: value for item in trigrams_list for key, value in item.items()}\n",
    "\n",
    "    return trigrams_dict\n",
    "\n",
    "# df.sort_values(by='freq', ascending=False).head(10)\n",
    "# 14594 lines with dot as second word\n",
    "\n",
    "trigrams_dict  = get_freq_trigrams()\n",
    "list(trigrams_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = max(trigrams_dict.values())\n",
    "b = min(trigrams_dict.values())\n",
    "\n",
    "c = 0\n",
    "d = 10\n",
    "\n",
    "def transform_num(x, a=a, b=b, c=c, d=d):\n",
    "    if x:\n",
    "        y = (x - a) * (d - c)/(b - a) + c\n",
    "        return round(y)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "transform_number(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10, ..., 5905] -> [0, ..., 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Data/document-aligned.v2/simple.txt', '\\t', header=None, names=['subject', 'num', 'sentence'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepair_X_y(paragraphs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for p in paragraphs:\n",
    "        X.append([word for word, _ in p])\n",
    "        y.append([boo for _, boo in p])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepair_X_y(paragraphs)\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_ = X_train_[:5000]\n",
    "X_test_ = X_test_[:1000]\n",
    "y_train = [token for x in y_train_[:5000] for token in x]\n",
    "y_test =[token for x in y_test_[:1000] for token in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class WordTokenizer(object):\n",
    "    \"\"\"\n",
    "    Custom Tokenizer\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab=nlp.vocab, tokenizer=None, return_doc=True):\n",
    "        self.vocab = vocab\n",
    "        self._word_tokenizer = tokenizer\n",
    "        self.return_doc = return_doc\n",
    "\n",
    "    def __call__(self, text):\n",
    "        if self._word_tokenizer:\n",
    "            words = self._word_tokenizer.tokenize(text)\n",
    "        else:\n",
    "            words = text.split(' ')\n",
    "        if self.return_doc:\n",
    "            spaces = [True] * len(words)\n",
    "            return Doc(self.vocab, words=words, spaces=spaces)\n",
    "        else:\n",
    "            return words\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner'])\n",
    "nlp.tokenizer = WordTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>capital</th>\n",
       "      <th>paragraph_boundary</th>\n",
       "      <th>number</th>\n",
       "      <th>dot</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>prev_lemma</th>\n",
       "      <th>prev_token_pos</th>\n",
       "      <th>prev_dep</th>\n",
       "      <th>prev_paragraph_boundary</th>\n",
       "      <th>prev_capital</th>\n",
       "      <th>next_lemma</th>\n",
       "      <th>next_token_pos</th>\n",
       "      <th>next_paragraph_boundary</th>\n",
       "      <th>next_capital</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>neighbors_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>compound</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Santa</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt; Santa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santa</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ana</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ana</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ana</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Santa</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>River</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Santa River</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>River</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ana</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ana is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>River</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>River a</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>amod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>major</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>is major</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>major</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>attr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>river</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a river</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>river</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>attr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>major</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>major in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>river</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>amod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>southern</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>river southern</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>southern</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in California</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>California</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>southern</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>southern ,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>California</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>California in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>, the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in United</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>United</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>pobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>States</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the States</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>States</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>United It</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>States</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>relcl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>begin</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>States begins</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>begin</td>\n",
       "      <td>VERB</td>\n",
       "      <td>relcl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>begin</td>\n",
       "      <td>VERB</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>San</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>begins San</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>San</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernardino</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>in Bernardino</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bernardino</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>San</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>County</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>San County</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>County</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernardino</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>cc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernardino and</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>County</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>conj</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>flow</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>County flows</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>flow</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>west</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and west</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>west</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>flow</td>\n",
       "      <td>VERB</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>about</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>flows about</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>about</td>\n",
       "      <td>ADV</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>west</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>west 100</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>about</td>\n",
       "      <td>ADV</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>about m</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>m</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>NUM</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100 to</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845979</th>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "      <td>aux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O'Brien</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>receive</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O'Brien receive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845980</th>\n",
       "      <td>receive</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would $</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845981</th>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>receive</td>\n",
       "      <td>VERB</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>receive 33</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845982</th>\n",
       "      <td>33</td>\n",
       "      <td>NUM</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>million</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$ million</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845983</th>\n",
       "      <td>million</td>\n",
       "      <td>NUM</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>NUM</td>\n",
       "      <td>cc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33 and</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845984</th>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>million</td>\n",
       "      <td>NUM</td>\n",
       "      <td>mark</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>that</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>million that</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845985</th>\n",
       "      <td>that</td>\n",
       "      <td>ADP</td>\n",
       "      <td>mark</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>poss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and his</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845986</th>\n",
       "      <td>-PRON-</td>\n",
       "      <td>DET</td>\n",
       "      <td>poss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>that</td>\n",
       "      <td>ADP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>that staff</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845987</th>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>DET</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>his of</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845988</th>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>almost</td>\n",
       "      <td>ADV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>staff almost</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845989</th>\n",
       "      <td>almost</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>of 200</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845990</th>\n",
       "      <td>200</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>almost</td>\n",
       "      <td>ADV</td>\n",
       "      <td>pobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>almost people</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845991</th>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>NUM</td>\n",
       "      <td>aux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200 would</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845992</th>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "      <td>aux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>receive</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>people receive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845993</th>\n",
       "      <td>receive</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would $</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845994</th>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>receive</td>\n",
       "      <td>VERB</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>receive 12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845995</th>\n",
       "      <td>12</td>\n",
       "      <td>NUM</td>\n",
       "      <td>compound</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>million</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>$ million</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845996</th>\n",
       "      <td>million</td>\n",
       "      <td>NUM</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NUM</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>conan</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12 conan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845997</th>\n",
       "      <td>conan</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>million</td>\n",
       "      <td>NUM</td>\n",
       "      <td>poss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O'Brien</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>million O'Brien</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845998</th>\n",
       "      <td>O'Brien</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>poss</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>conan</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'s</td>\n",
       "      <td>PART</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>conan 's</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845999</th>\n",
       "      <td>'s</td>\n",
       "      <td>PART</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O'Brien</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>amod</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>last</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O'Brien last</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846000</th>\n",
       "      <td>last</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'s</td>\n",
       "      <td>PART</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>show</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'s show</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846001</th>\n",
       "      <td>show</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>last</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>acl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>air</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>last aired</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846002</th>\n",
       "      <td>air</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>show</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>show on</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846003</th>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>air</td>\n",
       "      <td>VERB</td>\n",
       "      <td>pobj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>January</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>aired January</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846004</th>\n",
       "      <td>January</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>on 22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846005</th>\n",
       "      <td>22</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>January</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>January ,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846006</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>NUM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22 2010</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846007</th>\n",
       "      <td>2010</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>appos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;/p&gt;</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>, &lt;/p&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846008</th>\n",
       "      <td>&lt;/p&gt;</td>\n",
       "      <td>X</td>\n",
       "      <td>appos</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>NUM</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1846009 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lemma    pos       dep  capital  paragraph_boundary  number  \\\n",
       "0               <p>  PUNCT      ROOT        0                   1       0   \n",
       "1               the    DET       det        1                   0       0   \n",
       "2             Santa  PROPN  compound        1                   0       0   \n",
       "3               Ana  PROPN  compound        1                   0       0   \n",
       "4             River  PROPN     nsubj        1                   0       0   \n",
       "5                be   VERB     ccomp        0                   0       0   \n",
       "6                 a    DET       det        0                   0       0   \n",
       "7             major    ADJ      amod        0                   0       0   \n",
       "8             river   NOUN      attr        0                   0       0   \n",
       "9                in    ADP      prep        0                   0       0   \n",
       "10         southern    ADJ      amod        0                   0       0   \n",
       "11       California  PROPN      pobj        1                   0       0   \n",
       "12                ,  PUNCT     punct        0                   0       0   \n",
       "13               in    ADP      prep        0                   0       0   \n",
       "14              the    DET       det        0                   0       0   \n",
       "15           United  PROPN  compound        1                   0       0   \n",
       "16           States  PROPN      pobj        1                   0       0   \n",
       "17           -PRON-   PRON     nsubj        1                   0       0   \n",
       "18            begin   VERB     relcl        0                   0       0   \n",
       "19               in    ADP      prep        0                   0       0   \n",
       "20              San  PROPN  compound        1                   0       0   \n",
       "21       Bernardino  PROPN  compound        1                   0       0   \n",
       "22           County  PROPN      pobj        1                   0       0   \n",
       "23              and  CCONJ        cc        0                   0       0   \n",
       "24             flow   VERB      conj        0                   0       0   \n",
       "25             west    ADJ    advmod        0                   0       0   \n",
       "26            about    ADV  quantmod        0                   0       0   \n",
       "27              100    NUM    nummod        0                   0       1   \n",
       "28                m   NOUN      dobj        0                   0       0   \n",
       "29               to    ADP      prep        0                   0       0   \n",
       "...             ...    ...       ...      ...                 ...     ...   \n",
       "1845979       would   VERB       aux        0                   0       0   \n",
       "1845980     receive   VERB     ccomp        0                   0       0   \n",
       "1845981           $    SYM  quantmod        0                   0       0   \n",
       "1845982          33    NUM  compound        0                   0       1   \n",
       "1845983     million    NUM      dobj        0                   0       0   \n",
       "1845984         and  CCONJ        cc        0                   0       0   \n",
       "1845985        that    ADP      mark        0                   0       0   \n",
       "1845986      -PRON-    DET      poss        0                   0       0   \n",
       "1845987       staff   NOUN     nsubj        0                   0       0   \n",
       "1845988          of    ADP      prep        0                   0       0   \n",
       "1845989      almost    ADV    advmod        0                   0       0   \n",
       "1845990         200    NUM    nummod        0                   0       1   \n",
       "1845991      people   NOUN      pobj        0                   0       0   \n",
       "1845992       would   VERB       aux        0                   0       0   \n",
       "1845993     receive   VERB      conj        0                   0       0   \n",
       "1845994           $    SYM  quantmod        0                   0       0   \n",
       "1845995          12    NUM  compound        0                   0       1   \n",
       "1845996     million    NUM      dobj        0                   0       0   \n",
       "1845997       conan   NOUN    advmod        0                   0       0   \n",
       "1845998     O'Brien  PROPN      poss        1                   0       0   \n",
       "1845999          's   PART      case        0                   0       0   \n",
       "1846000        last    ADJ      amod        0                   0       0   \n",
       "1846001        show   NOUN      dobj        0                   0       0   \n",
       "1846002         air   VERB       acl        0                   0       0   \n",
       "1846003          on    ADP      prep        0                   0       0   \n",
       "1846004     January  PROPN      pobj        1                   0       0   \n",
       "1846005          22    NUM    nummod        0                   0       1   \n",
       "1846006           ,  PUNCT     punct        0                   0       0   \n",
       "1846007        2010    NUM    nummod        0                   0       1   \n",
       "1846008        </p>      X     appos        0                   1       0   \n",
       "\n",
       "         dot  is_punct  prev_lemma prev_token_pos  prev_dep  \\\n",
       "0          0         0                                  det   \n",
       "1          0         0         <p>          PUNCT  compound   \n",
       "2          0         0         the            DET  compound   \n",
       "3          0         0       Santa          PROPN     nsubj   \n",
       "4          0         0         Ana          PROPN     ccomp   \n",
       "5          0         0       River          PROPN       det   \n",
       "6          0         0          be           VERB      amod   \n",
       "7          0         0           a            DET      attr   \n",
       "8          0         0       major            ADJ      prep   \n",
       "9          0         0       river           NOUN      amod   \n",
       "10         0         0          in            ADP      pobj   \n",
       "11         0         0    southern            ADJ     punct   \n",
       "12         0         1  California          PROPN      prep   \n",
       "13         0         0           ,          PUNCT       det   \n",
       "14         0         0          in            ADP  compound   \n",
       "15         0         0         the            DET      pobj   \n",
       "16         0         0      United          PROPN     nsubj   \n",
       "17         0         0      States          PROPN     relcl   \n",
       "18         0         0      -PRON-           PRON      prep   \n",
       "19         0         0       begin           VERB  compound   \n",
       "20         0         0          in            ADP  compound   \n",
       "21         0         0         San          PROPN      pobj   \n",
       "22         0         0  Bernardino          PROPN        cc   \n",
       "23         0         0      County          PROPN      conj   \n",
       "24         0         0         and          CCONJ    advmod   \n",
       "25         0         0        flow           VERB  quantmod   \n",
       "26         0         0        west            ADJ    nummod   \n",
       "27         0         0       about            ADV      dobj   \n",
       "28         0         0         100            NUM      prep   \n",
       "29         0         0           m           NOUN       det   \n",
       "...      ...       ...         ...            ...       ...   \n",
       "1845979    0         0     O'Brien          PROPN     ccomp   \n",
       "1845980    0         0       would           VERB  quantmod   \n",
       "1845981    0         1     receive           VERB  compound   \n",
       "1845982    0         0           $            SYM      dobj   \n",
       "1845983    0         0          33            NUM        cc   \n",
       "1845984    0         0     million            NUM      mark   \n",
       "1845985    0         0         and          CCONJ      poss   \n",
       "1845986    0         0        that            ADP     nsubj   \n",
       "1845987    0         0      -PRON-            DET      prep   \n",
       "1845988    0         0       staff           NOUN    advmod   \n",
       "1845989    0         0          of            ADP    nummod   \n",
       "1845990    0         0      almost            ADV      pobj   \n",
       "1845991    0         0         200            NUM       aux   \n",
       "1845992    0         0      people           NOUN      conj   \n",
       "1845993    0         0       would           VERB  quantmod   \n",
       "1845994    0         1     receive           VERB  compound   \n",
       "1845995    0         0           $            SYM      dobj   \n",
       "1845996    0         0          12            NUM    advmod   \n",
       "1845997    0         0     million            NUM      poss   \n",
       "1845998    0         0       conan           NOUN      case   \n",
       "1845999    0         0     O'Brien          PROPN      amod   \n",
       "1846000    0         0          's           PART      dobj   \n",
       "1846001    0         0        last            ADJ       acl   \n",
       "1846002    0         0        show           NOUN      prep   \n",
       "1846003    0         0         air           VERB      pobj   \n",
       "1846004    0         0          on            ADP    nummod   \n",
       "1846005    0         0     January          PROPN     punct   \n",
       "1846006    0         1          22            NUM    nummod   \n",
       "1846007    0         0           ,          PUNCT     appos   \n",
       "1846008    0         0        2010            NUM             \n",
       "\n",
       "         prev_paragraph_boundary  prev_capital  next_lemma next_token_pos  \\\n",
       "0                              0             0         the            DET   \n",
       "1                              1             0       Santa          PROPN   \n",
       "2                              0             1         Ana          PROPN   \n",
       "3                              0             1       River          PROPN   \n",
       "4                              0             1          be           VERB   \n",
       "5                              0             1           a            DET   \n",
       "6                              0             0       major            ADJ   \n",
       "7                              0             0       river           NOUN   \n",
       "8                              0             0          in            ADP   \n",
       "9                              0             0    southern            ADJ   \n",
       "10                             0             0  California          PROPN   \n",
       "11                             0             0           ,          PUNCT   \n",
       "12                             0             1          in            ADP   \n",
       "13                             0             0         the            DET   \n",
       "14                             0             0      United          PROPN   \n",
       "15                             0             0      States          PROPN   \n",
       "16                             0             1      -PRON-           PRON   \n",
       "17                             0             1       begin           VERB   \n",
       "18                             0             1          in            ADP   \n",
       "19                             0             0         San          PROPN   \n",
       "20                             0             0  Bernardino          PROPN   \n",
       "21                             0             1      County          PROPN   \n",
       "22                             0             1         and          CCONJ   \n",
       "23                             0             1        flow           VERB   \n",
       "24                             0             0        west            ADJ   \n",
       "25                             0             0       about            ADV   \n",
       "26                             0             0         100            NUM   \n",
       "27                             0             0           m           NOUN   \n",
       "28                             0             0          to            ADP   \n",
       "29                             0             0         the            DET   \n",
       "...                          ...           ...         ...            ...   \n",
       "1845979                        0             1     receive           VERB   \n",
       "1845980                        0             0           $            SYM   \n",
       "1845981                        0             0          33            NUM   \n",
       "1845982                        0             0     million            NUM   \n",
       "1845983                        0             0         and          CCONJ   \n",
       "1845984                        0             0        that            ADP   \n",
       "1845985                        0             0      -PRON-            DET   \n",
       "1845986                        0             0       staff           NOUN   \n",
       "1845987                        0             0          of            ADP   \n",
       "1845988                        0             0      almost            ADV   \n",
       "1845989                        0             0         200            NUM   \n",
       "1845990                        0             0      people           NOUN   \n",
       "1845991                        0             0       would           VERB   \n",
       "1845992                        0             0     receive           VERB   \n",
       "1845993                        0             0           $            SYM   \n",
       "1845994                        0             0          12            NUM   \n",
       "1845995                        0             0     million            NUM   \n",
       "1845996                        0             0       conan           NOUN   \n",
       "1845997                        0             0     O'Brien          PROPN   \n",
       "1845998                        0             0          's           PART   \n",
       "1845999                        0             1        last            ADJ   \n",
       "1846000                        0             0        show           NOUN   \n",
       "1846001                        0             0         air           VERB   \n",
       "1846002                        0             0          on            ADP   \n",
       "1846003                        0             0     January          PROPN   \n",
       "1846004                        0             0          22            NUM   \n",
       "1846005                        0             1           ,          PUNCT   \n",
       "1846006                        0             0        2010            NUM   \n",
       "1846007                        0             0        </p>              X   \n",
       "1846008                        0             0                              \n",
       "\n",
       "         next_paragraph_boundary  next_capital        neighbors  \\\n",
       "0                              0             1                    \n",
       "1                              0             1        <p> Santa   \n",
       "2                              0             1          The Ana   \n",
       "3                              0             1      Santa River   \n",
       "4                              0             0           Ana is   \n",
       "5                              0             0          River a   \n",
       "6                              0             0         is major   \n",
       "7                              0             0          a river   \n",
       "8                              0             0         major in   \n",
       "9                              0             0   river southern   \n",
       "10                             0             1    in California   \n",
       "11                             0             0       southern ,   \n",
       "12                             0             0    California in   \n",
       "13                             0             0            , the   \n",
       "14                             0             1        in United   \n",
       "15                             0             1       the States   \n",
       "16                             0             1        United It   \n",
       "17                             0             0    States begins   \n",
       "18                             0             0            It in   \n",
       "19                             0             1       begins San   \n",
       "20                             0             1    in Bernardino   \n",
       "21                             0             1       San County   \n",
       "22                             0             0   Bernardino and   \n",
       "23                             0             0     County flows   \n",
       "24                             0             0         and west   \n",
       "25                             0             0      flows about   \n",
       "26                             0             0         west 100   \n",
       "27                             0             0          about m   \n",
       "28                             0             0           100 to   \n",
       "29                             0             0            m the   \n",
       "...                          ...           ...              ...   \n",
       "1845979                        0             0  O'Brien receive   \n",
       "1845980                        0             0          would $   \n",
       "1845981                        0             0       receive 33   \n",
       "1845982                        0             0        $ million   \n",
       "1845983                        0             0           33 and   \n",
       "1845984                        0             0     million that   \n",
       "1845985                        0             0          and his   \n",
       "1845986                        0             0       that staff   \n",
       "1845987                        0             0           his of   \n",
       "1845988                        0             0     staff almost   \n",
       "1845989                        0             0           of 200   \n",
       "1845990                        0             0    almost people   \n",
       "1845991                        0             0        200 would   \n",
       "1845992                        0             0   people receive   \n",
       "1845993                        0             0          would $   \n",
       "1845994                        0             0       receive 12   \n",
       "1845995                        0             0        $ million   \n",
       "1845996                        0             0         12 conan   \n",
       "1845997                        0             1  million O'Brien   \n",
       "1845998                        0             0         conan 's   \n",
       "1845999                        0             0     O'Brien last   \n",
       "1846000                        0             0          's show   \n",
       "1846001                        0             0       last aired   \n",
       "1846002                        0             0          show on   \n",
       "1846003                        0             1    aired January   \n",
       "1846004                        0             0            on 22   \n",
       "1846005                        0             0        January ,   \n",
       "1846006                        0             0          22 2010   \n",
       "1846007                        1             0           , </p>   \n",
       "1846008                        0             0                    \n",
       "\n",
       "        neighbors_group  \n",
       "0                        \n",
       "1                        \n",
       "2                        \n",
       "3                        \n",
       "4                        \n",
       "5                        \n",
       "6                        \n",
       "7                        \n",
       "8                        \n",
       "9                        \n",
       "10                       \n",
       "11                       \n",
       "12                       \n",
       "13                       \n",
       "14                       \n",
       "15                       \n",
       "16                       \n",
       "17                       \n",
       "18                       \n",
       "19                       \n",
       "20                       \n",
       "21                       \n",
       "22                       \n",
       "23                       \n",
       "24                       \n",
       "25                       \n",
       "26                       \n",
       "27                       \n",
       "28                       \n",
       "29                       \n",
       "...                 ...  \n",
       "1845979                  \n",
       "1845980                  \n",
       "1845981                  \n",
       "1845982                  \n",
       "1845983                  \n",
       "1845984                  \n",
       "1845985                  \n",
       "1845986                  \n",
       "1845987                  \n",
       "1845988                  \n",
       "1845989                  \n",
       "1845990                  \n",
       "1845991                  \n",
       "1845992                  \n",
       "1845993                  \n",
       "1845994                  \n",
       "1845995                  \n",
       "1845996                  \n",
       "1845997                  \n",
       "1845998                  \n",
       "1845999                  \n",
       "1846000                  \n",
       "1846001                  \n",
       "1846002              20  \n",
       "1846003                  \n",
       "1846004                  \n",
       "1846005                  \n",
       "1846006                  \n",
       "1846007                  \n",
       "1846008                  \n",
       "\n",
       "[1846009 rows x 19 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processed(docs):\n",
    "    \n",
    "    tokens = []\n",
    "    for doc in docs:\n",
    "        doc_tokens = [(token.text, token.lemma_, token.pos_, token.dep_) for token in nlp(\" \".join(doc))]\n",
    "        tokens.extend(doc_tokens)\n",
    "    \n",
    "    df = pd.DataFrame(tokens, columns=['token', 'lemma', 'pos', 'dep'])\n",
    "    df['capital'] = df['token'].map(lambda t: 1 if t.istitle() else 0)\n",
    "    df['paragraph_boundary'] = df['token'].map(lambda t: 1 if t in ('<p>', '</p>') else 0)\n",
    "    df['number'] = df['token'].map(lambda t: 1 if t.isnumeric() else 0)\n",
    "    df['dot'] = df['token'].map(lambda t: 1 if t == '.' else 0)\n",
    "    df['is_punct'] = df['token'].map(lambda t: 1 if str(t) in string.punctuation else 0)\n",
    "    \n",
    "    df['prev_lemma'] = df['lemma'].shift(1)\n",
    "    df['prev_token_pos'] = df['pos'].shift(1)\n",
    "    df['prev_dep'] = df['dep'].shift(1)\n",
    "    df['prev_paragraph_boundary'] = df['token'].shift(1).map(lambda t: 1 if t in ('<p>', '</p>') else 0)\n",
    "    df['prev_capital'] = df['token'].shift(1).map(lambda t: 1 if str(t).istitle() else 0)\n",
    "    \n",
    "    df['next_lemma'] = df['lemma'].shift(-1)\n",
    "    df['next_token_pos'] = df['pos'].shift(-1)\n",
    "    df['prev_dep'] = df['dep'].shift(-1)\n",
    "    df['next_paragraph_boundary'] = df['token'].shift(-1).map(lambda t: 1 if t in ('<p>', '</p>') else 0)\n",
    "    df['next_capital'] = df['token'].shift(-1).map(lambda t: 1 if str(t).istitle() else 0)\n",
    "    \n",
    "    # Feature get frequent trigams list\n",
    "    df['neighbors'] = df['token'].shift(1) + ' ' + df['token'].shift(-1)\n",
    "    df['neighbors_group'] = df['neighbors'].map(lambda x: transform_num(trigrams_dict.get(x)))\n",
    "    \n",
    "    return df.fillna('').drop(['token', ], axis=1) # 'neighbors'\n",
    "\n",
    "processed(X_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "\n",
    "X = processed(X_train_)\n",
    "X_train = vectorizer.fit_transform(X.to_dict('records'))\n",
    "\n",
    "X = processed(X_test_)\n",
    "X_test = vectorizer.transform(X.to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/olhasempienv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.994     0.988    345759\n",
      "           1      0.869     0.669     0.756     19470\n",
      "\n",
      "   micro avg      0.977     0.977     0.977    365229\n",
      "   macro avg      0.925     0.832     0.872    365229\n",
      "weighted avg      0.976     0.977     0.976    365229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrc = LogisticRegression(random_state=42, solver=\"lbfgs\", multi_class=\"multinomial\", max_iter=800)\n",
    "\n",
    "lrc.fit(X_train, y_train)\n",
    "y_pred = lrc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, digits=3)) #, labels=None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "add a feature trigrams\n",
    "\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "           0      0.982     0.994     0.988    345759\n",
    "           1      0.869     0.670     0.756     19470\n",
    "\n",
    "   micro avg      0.977     0.977     0.977    365229\n",
    "   macro avg      0.925     0.832     0.872    365229\n",
    "weighted avg      0.976     0.977     0.976    365229"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0      0.981     0.994     0.988    345759\n",
    "           1      0.859     0.665     0.750     19470\n",
    "\n",
    "   micro avg      0.976     0.976     0.976    365229\n",
    "   macro avg      0.920     0.829     0.869    365229\n",
    "weighted avg      0.975     0.976     0.975    365229"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.994     0.991     0.992      4942\n",
      "        True      0.735     0.806     0.769       155\n",
      "\n",
      "   micro avg      0.985     0.985     0.985      5097\n",
      "   macro avg      0.865     0.899     0.881      5097\n",
      "weighted avg      0.986     0.985     0.986      5097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('Data/run-on-test.json') as file:\n",
    "    data = json.load(file)\n",
    "    data = [[['<p>', False]] + i + [['</p>', False]] for i in data]\n",
    "    \n",
    "X_val_, y_val = prepair_X_y(data)\n",
    "y_val =[token for x in y_val[:500] for token in x]\n",
    "X = processed(X_val_)\n",
    "X_val = vectorizer.transform(X.to_dict('records'))\n",
    "\n",
    "y_pred = lrc.predict(X_val)\n",
    "\n",
    "print(classification_report(y_true=y_val, y_pred=y_pred, digits=3)) #, labels=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1-score rised from 0.742 to 0.769 of True label after adding the feature with trigrams.\n",
    "\n",
    "Before\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False      0.993     0.990     0.991      4942\n",
    "        True      0.708     0.781     0.742       155\n",
    "\n",
    "   micro avg      0.984     0.984     0.984      5097\n",
    "   macro avg      0.850     0.885     0.867      5097\n",
    "weighted avg      0.984     0.984     0.984      5097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lemma', 'pos', 'dep', 'capital', 'paragraph_boundary', 'number', 'dot',\n",
       "       'is_punct', 'prev_lemma', 'prev_token_pos', 'prev_dep',\n",
       "       'prev_paragraph_boundary', 'prev_capital', 'next_lemma',\n",
       "       'next_token_pos', 'next_paragraph_boundary', 'next_capital',\n",
       "       'neighbors', 'neighbors_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final features of the model:\n",
    "1. lemma\n",
    "2. pos\n",
    "3. dep\n",
    "4. capital\n",
    "5. paragraph_boundary\n",
    "6. number\n",
    "7. dot\n",
    "8. is_punct\n",
    "9. prev_lemma\n",
    "10. prev_token_pos\n",
    "11. prev_dep\n",
    "12. prev_paragraph_boundary\n",
    "13. prev_capital\n",
    "14. next_lemma\n",
    "15. next_token_pos\n",
    "16. next_paragraph_boundary\n",
    "17. next_capital\n",
    "18. neighbors\n",
    "19. neighbors_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
